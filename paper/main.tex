
\documentclass[10pt]{article} % For LaTeX2e
\usepackage[preprint]{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
%\usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{url}
\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{lipsum}

\definecolor{xlinkcolor}{rgb}{0.7752941176470588, 0.22078431372549023, 0.2262745098039215}

\usepackage[
pdfnewwindow=true,      % links in new window
colorlinks=true,    % false: boxed links; true: colored links
linkcolor=xlinkcolor,     % color of internal links
citecolor=xlinkcolor,     % color of links to bibliography
filecolor=xlinkcolor,  % color of file links
urlcolor=xlinkcolor,      % color of external links
final=true,
]{hyperref}



\title{\textsc{HubbleCLIP}: Associating Astronomical Observations and Natural Language with Multi-modal Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Siddharth Mishra-Sharma \email \href{mailto:smsharma@mit.edu}{smsharma@mit.edu} \\
      \addr The NSF AI Institute for Artificial Intelligence and Fundamental Interactions\\
      Center for Theoretical Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA \\
      Department of Physics, Harvard University, Cambridge, MA 02138, USA
      \AND
      \name Yiding Song \email \href{mailto:ydsong@mit.edu}{ydsong@mit.edu} \\
      \addr The NSF AI Institute for Artificial Intelligence and Fundamental Interactions\\
      Department of Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA \\
      \AND
      \name Jesse Thaler \email \href{mailto:jthaler@mit.edu}{jthaler@mit.edu} \\
      \addr The NSF AI Institute for Artificial Intelligence and Fundamental Interactions\\
      Center for Theoretical Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA \\
}
% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{MM}  % Insert correct month for camera-ready version
\def\year{YYYY} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version

\newcommand{\datafolder}[1]{\def\thedatafolder{#1}}


\begin{document}


\maketitle

\begin{abstract}
We present a multi-modal model which associates astronomical observations imaged by the \emph{Hubble} Space Telescope (HST) with natural language. The model is fine-tuned from a base CLIP model using summarized proposal abstracts corresponding to HST observations. We show that the model embodies a meaningful joint representation between observations and text through experiments targeting observation retrieval (i.e., retrieving most relevant set of observations using natural language queries) and description retrieval (i.e., querying the most relevant natural language descriptions using observations). The model demonstrates the potential for using generalist rather than task-specific models for astrophysics research, in particular by leveraging text as an interface.
\end{abstract}

\section{Introduction}
\label{sec:intro}

\lipsum[1-2]

\section{Dataset and Processing}
\label{sec:dataset}

\subsection{Summarization via guided generation}
\label{sec:summarization}

\section{Methodology}
\label{sec:methodology}

\subsection{Language-Image Pre-training}
\label{sec:pretraining}

\subsection{Pre-trained CLIP Model}
\label{sec:clip}

\subsection{Fine-tuning Objectives}
\label{sec:finetuning}

\section{Results and Discussion}
\label{sec:results}

\subsection{Fine-tuned Retrieval Accuracy}
\label{sec:retrieval_acc}

\subsection{`Zero-shot' Hypothesis and Object Retrieval}
\label{sec:zero_shot}

\subsection{Text-to-Image Retrieval}
\label{sec:tti}


\cite{Hinton06}

\datafolder{./plots/data/} % Set your folder path here

\begin{table}[h!]
      \centering
      \begin{tabular}{m{0.21\textwidth} p{1.9cm} p{1.9cm} m{8cm}}
          \toprule
          \centering \bfseries Image & \centering \bfseries Obs. cycle & \centering \bfseries Prop. ID & \centering \bfseries Summarized abstract \tabularnewline
          \midrule
          \centering \includegraphics[width=0.2\textwidth]{\thedatafolder/img_0.pdf} & \centering \input{\thedatafolder/cycle_0.txt} & \centering \input{\thedatafolder/id_0.txt} &  {\scriptsize \input{\thedatafolder/sum_0.txt}} \tabularnewline
          \midrule
          \centering \includegraphics[width=0.2\textwidth]{\thedatafolder/img_1.pdf} & \centering \input{\thedatafolder/cycle_1.txt} & \centering \input{\thedatafolder/id_1.txt} &  {\scriptsize \input{\thedatafolder/sum_1.txt}} \tabularnewline
          \midrule
          \centering \includegraphics[width=0.2\textwidth]{\thedatafolder/img_2.pdf} & \centering \input{\thedatafolder/cycle_2.txt} & \centering \input{\thedatafolder/id_2.txt} &  {\scriptsize \input{\thedatafolder/sum_2.txt}} \tabularnewline
          \midrule
          \centering \includegraphics[width=0.2\textwidth]{\thedatafolder/img_3.pdf} & \centering \input{\thedatafolder/cycle_3.txt} & \centering \input{\thedatafolder/id_3.txt} &  {\scriptsize \input{\thedatafolder/sum_3.txt}} \tabularnewline
          \bottomrule
      \end{tabular}
      \caption{Data overview}
  \end{table}
  
  
  
  
    

% \begin{figure*}[!h]
% \includegraphics[width=0.95\textwidth]{example-image-a}
% \caption{Overview of dataset}
% \label{fig:dataset}
% \end{figure*}

\begin{figure*}[!h]
\includegraphics[width=0.95\textwidth]{plots/retrieval_acc.pdf}
\caption{Retrieval accuracy}
\label{fig:retrieval_acc}
\end{figure*}

\begin{figure*}[!h]
\includegraphics[width=0.95\textwidth]{plots/itt.pdf}
\caption{Retrieval accuracy}
\label{fig:itt}
\end{figure*}

\begin{figure*}[!h]
\includegraphics[width=0.95\textwidth]{plots/tti_base.pdf}
\caption{Retrieval accuracy}
\label{fig:tti}
\end{figure*}

\begin{figure*}[!h]
\includegraphics[width=0.95\textwidth]{plots/tti.pdf}
\caption{Retrieval accuracy}
\label{fig:tti_base}
\end{figure*}

\subsubsection*{Broader Impact Statement}
In this optional section, TMLR encourages authors to discuss possible repercussions of their work,
notably any potential negative impact that a user of this research should be aware of. 
Authors should consult the TMLR Ethics Guidelines available on the TMLR website
for guidance on how to approach this subject.

\subsubsection*{Author Contributions}
If you'd like to, you may include a section for author contributions as is done
in many journals. This is optional and at the discretion of the authors. Only add
this information once your submission is accepted and deanonymized. 

\subsubsection*{Acknowledgments}
Use unnumbered third level headings for the acknowledgments. All
acknowledgments, including those to funding agencies, go at the end of the paper.
Only add this information once your submission is accepted and deanonymized. 

\bibliography{main}
\bibliographystyle{tmlr}

\appendix
\section{Appendix}
You may include other additional sections here.

\end{document}
