{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17ecbac5-bcc9-4f3e-b8fd-0bd6b88625e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import outlines\n",
    "import outlines.models as models\n",
    "import outlines.text as text\n",
    "from outlines.text.generate.sample import multinomial\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from pydantic import BaseModel, Field, constr, conlist\n",
    "from enum import Enum\n",
    "\n",
    "from utils.summarize_utils import ConstrainedResponseHST, prompt_fn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cf65b8-0e2a-4ab6-a0eb-78d241c47911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406877e9c2a7464fa99456c2b8895a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replacing layers...: 100%|█| 32/32 [00:02<00:00, 13.59it/s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/739 [00:00<?, ?w/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers...: 100%|███| 32/32 [00:04<00:00,  6.46it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model = models.awq(\"TheBloke/Mistral-7B-OpenOrca-AWQ\")\n",
    "model = models.awq(\"TheBloke/OpenHermes-2.5-Mistral-7B-AWQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0c55987-e2d5-484d-bfc4-0fba6ff31a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"mosaicml/mpt-7b-8k-instruct\"\n",
    "# model_name = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "\n",
    "# config = transformers.AutoConfig.from_pretrained(\n",
    "#     model_name, trusmt_remote_code=True\n",
    "# )\n",
    "# config.init_device = \"meta\"\n",
    "# model = models.transformers(\n",
    "    \n",
    "#     model_name=model_name\",\n",
    "#     device=\"cuda\",\n",
    "#     model_kwargs={\n",
    "#         \"config\": config,\n",
    "#         \"trust_remote_code\": True,\n",
    "#         \"torch_dtype\": torch.bfloat16,\n",
    "#         \"device_map\": {\"\": 0},\n",
    "#         \"cache_dir\": \"/n/holystore01/LABS/iaifi_lab/Users/smsharma/hf_cache/\"\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8f4406a0-bb37-429f-9311-3e44df9a6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = \"\"\"\n",
    "We propose to observe ultraluminous X-ray sources which are located near\n",
    "objects bright both in the X-rays and the optical using Chandra and HST. The\n",
    "presence of these reference objects will allow us to tie the x-ray and optical\n",
    "references frames and achieve 0.1-0.2 arcsecond relative position accuracy in\n",
    "searching for optical counterparts to the ultraluminous x-ray sources. This\n",
    "will be a significant improvement over the accuracy previously obtained for\n",
    "most ULXs {limited by Chandra's absolute astrometry} and will should permit\n",
    "identification of individual counterparts.\n",
    "\"\"\"\n",
    "\n",
    "# abstract = \"\"\"\n",
    "# We propose a comprehensive optical, UV, and X-ray investigation of the unique\n",
    "# galaxy POX 52. POX 52 is a Seyfert 1 galaxy with unprecedented properties: its\n",
    "# host galaxy appears to be a dwarf elliptical, and its stellar velocity\n",
    "# dispersion is only 36 km/s. The stellar velocity dispersion and the broad\n",
    "# emission-line widths both suggest a black hole mass of order 10^5 solar\n",
    "# masses, placing POX 52 in a region of AGN parameter space that is almost\n",
    "# completely unexplored at present. We request ACS/HRC imaging to perform a\n",
    "# definitive measurement of the host galaxy structure; STIS UV and optical\n",
    "# spectroscopy to study the nonstellar continuum and the structure of the\n",
    "# broad-line region; and Chandra ACS imaging to detect the X-ray emission from\n",
    "# the nucleus and investigate its spectral and variability properties. The\n",
    "# results of this program will give a detailed understanding of the host galaxy\n",
    "# and accretion properties of one of the very few known black holes in the mass\n",
    "# range around 10^5 solar masses.\n",
    "# \"\"\"\n",
    "\n",
    "# abstract = \"\"\"\n",
    "# The observed optical depths to microlensing of stars in the Galactic bulge are\n",
    "# difficult to reconcile with our present understanding of Galactic dynamics.\n",
    "# The main source of uncertainty in those comparisons is now shifting from\n",
    "# microlensing measurements to the dynamical models of the Galactic bar. We\n",
    "# propose to constrain the Galactic bar models with proper motion observations\n",
    "# of Bulge stars that underwent microlensing by determining both the kinematic\n",
    "# identity of the microlensed sources and the importance of streaming motions.\n",
    "# The lensed stars are typically farther than randomly selected stars.\n",
    "# Therefore, our proper motion determinations for 36 targeted MACHO events will\n",
    "# provide valuable constraints on the dynamics of bulge stars as a function of\n",
    "# distance. The first epoch data for our proposed events is already available in\n",
    "# the HST archive so the project can be completed within a single HST cycle. The\n",
    "# exceptional spatial resolution of HST is essential for completion of the\n",
    "# project. Constraints on te total mass in the bulge will ultimately lead to\n",
    "# the determination of the amount of dark matter in inner Galaxy.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03275217-0cc5-4e2d-8c48-b552bf03202b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstrainedResponseHST(objects_and_phenomena=\"ultraluminous X-ray sources, X-ray and optical bright objects, reference frames, optical counterparts, Chandra's absolute astrometry\", science_use_cases='tie X-ray and optical references frames, achieve 0.1-0.2 arcsecond relative position accuracy, identification of individual counterparts')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_fn(abstract)\n",
    "generator = text.generate.json(model, ConstrainedResponseHST, sampler=multinomial)\n",
    "sequence = generator(prompt)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4472af05-b74f-480c-a669-fb7dba94bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = text.generate.continuation(model)\n",
    "# sequence = generator(prompt)\n",
    "# sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "816e421f-33d6-43f7-b6a1-1831a3c0cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.abstract_utils import read_abstracts_file\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "filename = \"../data/abstracts.cat\"\n",
    "\n",
    "abstracts_df = read_abstracts_file(filename)\n",
    "\n",
    "# Drop rows with missing Cycle\n",
    "abstracts_df = abstracts_df.dropna(subset=['Cycle'])\n",
    "abstracts_df = abstracts_df[abstracts_df['Cycle'] != '']\n",
    "\n",
    "# Convert Cycle and ID to int\n",
    "abstracts_df['Cycle'] = abstracts_df['Cycle'].astype(int)\n",
    "abstracts_df['ID'] = abstracts_df['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "456f532c-f479-403c-a520-494161976282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# data_folder = \"../data/observations_v1/\"\n",
    "\n",
    "# def get_abstracts(data_folder, max_abstracts=10):\n",
    "    \n",
    "#     # Lists to store results\n",
    "#     proposal_id_list = []\n",
    "#     objects_list = []\n",
    "#     science_list = []\n",
    "\n",
    "#     # Collect directories that contain .jpg files and match the \"proposal_\" pattern, excluding unwanted directories\n",
    "#     directories_with_images = [os.path.join(r, d)\n",
    "#                                for r, dirs, files in os.walk(data_folder)\n",
    "#                                for d in dirs\n",
    "#                                if d.startswith(\"proposal_\") and not d.endswith('.ipynb_checkpoints')]\n",
    "\n",
    "#     # Walk through data folder\n",
    "#     for directory in tqdm(directories_with_images[:max_abstracts]):\n",
    "#         proposal_id = directory.split(\"proposal_\")[-1]  # Extract proposal id from the directory name\n",
    "\n",
    "#         # Extract abstract using the dataframe\n",
    "#         abstract = abstracts_df[abstracts_df[\"ID\"] == int(proposal_id)][\"Abstract\"].values[0]\n",
    "\n",
    "#         prompt = prompt_fn(abstract)\n",
    "#         generator = text.generate.json(model, ConstrainedResponseHST)\n",
    "#         result = generator(prompt)\n",
    "#         print(result)\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         proposal_id_list.append(proposal_id)\n",
    "#         science_list.append(result.science_use_cases)\n",
    "#         objects_list.append(result.objects_and_phenomena)\n",
    "\n",
    "#     return proposal_id_list, objects_list, science_list\n",
    "        \n",
    "# proposal_id_list, objects_list, science_list = get_abstracts(data_folder)\n",
    "\n",
    "# # Create a DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'proposal_id': proposal_id_list,\n",
    "#     'objects_phenomena': objects_list,\n",
    "#     'science_use_cases': science_list\n",
    "# })\n",
    "\n",
    "# df.to_csv('../data/summary_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81196e25-909c-418e-afe9-17b8fb620ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
