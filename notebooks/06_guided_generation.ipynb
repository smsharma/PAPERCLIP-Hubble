{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ecbac5-bcc9-4f3e-b8fd-0bd6b88625e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import outlines\n",
    "import outlines.models as models\n",
    "import outlines.text as text\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from pydantic import BaseModel, Field, constr, conlist\n",
    "from enum import Enum\n",
    "\n",
    "from utils.summarize_utils import ConstrainedResponseHST, prompt_fn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c55987-e2d5-484d-bfc4-0fba6ff31a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e62ed3dd09c47308a326a813fcbd64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name, trust_remote_code=True, asd=True,\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = models.transformers(\n",
    "    \n",
    "    model_name=model_name,\n",
    "    model_kwargs={\n",
    "        \"config\": config,\n",
    "        \"quantization_config\": bnb_config,\n",
    "        \"trust_remote_code\": True,\n",
    "        \"device_map\": \"auto\",\n",
    "        \"load_in_4bit\": True,\n",
    "        \"cache_dir\": \"/n/holystore01/LABS/iaifi_lab/Users/smsharma/hf_cache/\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4406a0-bb37-429f-9311-3e44df9a6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = \"\"\"\n",
    "The observed optical depths to microlensing of stars in the Galactic bulge are\n",
    "difficult to reconcile with our present understanding of Galactic dynamics.\n",
    "The main source of uncertainty in those comparisons is now shifting from\n",
    "microlensing measurements to the dynamical models of the Galactic bar. We\n",
    "propose to constrain the Galactic bar models with proper motion observations\n",
    "of Bulge stars that underwent microlensing by determining both the kinematic\n",
    "identity of the microlensed sources and the importance of streaming motions.\n",
    "The lensed stars are typically farther than randomly selected stars.\n",
    "Therefore, our proper motion determinations for 36 targeted MACHO events will\n",
    "provide valuable constraints on the dynamics of bulge stars as a function of\n",
    "distance. The first epoch data for our proposed events is already available in\n",
    "the HST archive so the project can be completed within a single HST cycle. The\n",
    "exceptional spatial resolution of HST is essential for completion of the\n",
    "project. Constraints on te total mass in the bulge will ultimately lead to\n",
    "the determination of the amount of dark matter in inner Galaxy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b008ad90-d792-4a51-8472-7475a8f3fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@outlines.prompt\n",
    "def prompt_fn(abstract, query):\n",
    "     \"\"\"[INST]\n",
    "You are an expert astrophysicist, with broad expertise across observational and theoretical astrophysics.\n",
    "\n",
    "Abstract: \"{{abstract}}\"\n",
    "Query: \"{{query}}\"\n",
    "\n",
    "The above is an abstract for a proposed observation taken by the Hubble Space Telescope (labeled \"Abstract\"), and an object or concept (labeled \"Query\").\n",
    "\n",
    "Could the observations corresponding to the abstract contain the query? Be precise, and do not contain related concepts or objects. \n",
    "\n",
    "Your response should be either True or False. Only return True if the query is closely related to the abstract, and the downstream observation could be relevant to the query.\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d00c9821-8782-471b-97d5-26ce220c1f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc2509899d642fd9c3519d8463ae1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8651506adab447ab9d0fcea5bccabf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26358348d66c4b0db40615180d400c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open the file in read mode\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "type_list = [\"base\", \"ft\", \"tfid\"]\n",
    "\n",
    "bool_list = np.zeros((3, 10, 10))\n",
    "\n",
    "for idx_type, type in enumerate(type_list):\n",
    "\n",
    "    for idx in tqdm(range(10)):\n",
    "\n",
    "        with open(f'eval_quant/captions_{type}_{idx}.txt', 'r') as file:\n",
    "            # Read the lines from the file\n",
    "            captions = file.readlines()\n",
    "        \n",
    "        with open(f'eval_quant/queries.txt', 'r') as file:\n",
    "            # Read the lines from the file\n",
    "            queries = file.readlines()\n",
    "        \n",
    "        # Strip any trailing newline characters\n",
    "        captions = [caption.strip() for caption in captions]\n",
    "        \n",
    "        # Print the loaded captions\n",
    "        for idx_cap, caption in enumerate(captions):\n",
    "            prompt = prompt_fn(caption, queries[idx])\n",
    "            generator = outlines.generate.format(model, bool)\n",
    "            sequence = generator(prompt)\n",
    "            bool_list[idx_type, idx, idx_cap] = 1 if sequence == 'True' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5de7e68-d2a3-43fe-8540-81afff8a56e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.76, 0.82)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_list[0].sum() / 100, bool_list[1].sum() / 100, bool_list[2].sum() / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "03275217-0cc5-4e2d-8c48-b552bf03202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = prompt_fn(abstract, \"bulge stars\")\n",
    "# generator = outlines.generate.format(model, bool)\n",
    "# sequence = generator(prompt)\n",
    "# sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81196e25-909c-418e-afe9-17b8fb620ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smsharma-outlines] *",
   "language": "python",
   "name": "conda-env-smsharma-outlines-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
