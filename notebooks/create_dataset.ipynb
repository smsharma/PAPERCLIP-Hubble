{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_abstracts_file(filename):\n",
    "    abstracts = []\n",
    "    abstract = {}\n",
    "    inside_abstract = False  # Flag to check if we're inside an abstract\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('-----'):\n",
    "                if abstract:  # If abstract has content, append to list\n",
    "                    abstracts.append(abstract)\n",
    "                    abstract = {}\n",
    "                    inside_abstract = False  # Reset the flag\n",
    "            else:\n",
    "                # Check for known properties\n",
    "                property_starts = ['Prop. Type:', 'Category:', 'ID:', 'Cycle:', 'Title:', 'PI:']\n",
    "                \n",
    "                if any(line.startswith(prop) for prop in property_starts) and not inside_abstract:\n",
    "                    if 'Prop. Type' in abstract and line.startswith('Prop. Type:'):\n",
    "                        # If a new abstract starts without delimiter, assume previous one ended\n",
    "                        abstracts.append(abstract)\n",
    "                        abstract = {}\n",
    "                    \n",
    "                    if line.startswith('Prop. Type:'):\n",
    "                        abstract['Prop. Type'] = line.split(':', 1)[1].strip()\n",
    "                    elif line.startswith('Category:'):\n",
    "                        abstract['Category'] = line.split(':', 1)[1].strip()\n",
    "                    elif line.startswith('ID:'):\n",
    "                        id_val = line.split(':', 1)[1].strip()\n",
    "                        try:\n",
    "                            abstract['ID'] = int(id_val)\n",
    "                        except ValueError:\n",
    "                            abstract['ID'] = id_val\n",
    "                    elif line.startswith('Cycle:'):\n",
    "                        cycle_val = line.split(':', 1)[1].strip()\n",
    "                        try:\n",
    "                            abstract['Cycle'] = int(cycle_val)\n",
    "                        except ValueError:\n",
    "                            abstract['Cycle'] = cycle_val\n",
    "                    elif line.startswith('Title:'):\n",
    "                        abstract['Title'] = line.split(':', 1)[1].strip()\n",
    "                    elif line.startswith('PI:'):\n",
    "                        abstract['PI'] = line.split(':', 1)[1].strip()\n",
    "                else:\n",
    "                    # If none of the known properties are found, we treat the line as part of the abstract\n",
    "                    abstract['Abstract'] = abstract.get('Abstract', '') + ' ' + line\n",
    "                    inside_abstract = True  # Set the flag indicating we're inside an abstract\n",
    "                \n",
    "    # After loop ends, check if there's any remaining content in the abstract dictionary\n",
    "    if abstract:\n",
    "        abstracts.append(abstract)\n",
    "\n",
    "    df = pd.DataFrame(abstracts)\n",
    "    \n",
    "    return df                \n",
    "\n",
    "filename = \"../data/abstracts.cat\"\n",
    "abstracts_df = read_abstracts_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prop. Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Title</th>\n",
       "      <th>PI</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>CAL/WFC3</td>\n",
       "      <td></td>\n",
       "      <td>13200.0</td>\n",
       "      <td>30</td>\n",
       "      <td>WFC3 SS Activation Test</td>\n",
       "      <td>John MacKenty</td>\n",
       "      <td>Part of side switch activities.  This progra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prop. Type Category       ID Cycle                    Title  \\\n",
       "3139   CAL/WFC3           13200.0    30  WFC3 SS Activation Test   \n",
       "\n",
       "                 PI                                           Abstract  \n",
       "3139  John MacKenty    Part of side switch activities.  This progra...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_df[abstracts_df['ID'] == 13200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = abstracts_df.dropna(subset=['Cycle'])\n",
    "abstracts_df = abstracts_df[abstracts_df['Cycle'] != '']\n",
    "\n",
    "abstracts_df['Cycle'] = abstracts_df['Cycle'].astype(int)\n",
    "abstracts_df['ID'] = abstracts_df['ID'].astype(int)\n",
    "abstracts_cycle_df = abstracts_df[(abstracts_df['Cycle'] >= 25) & (abstracts_df['Cycle'] <= 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    533\n",
       "30    413\n",
       "29    411\n",
       "28    404\n",
       "27    363\n",
       "31    261\n",
       "26    222\n",
       "Name: Cycle, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_cycle_df['Cycle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_ids = abstracts_cycle_df['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../\")\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from scripts.download_data import download_data\n",
    "\n",
    "# proposal_id = 15922\n",
    "# n_max_images = 10\n",
    "# max_resolution = 512\n",
    "# seed = 42\n",
    "\n",
    "\n",
    "# for proposal_id in tqdm(abstract_ids):\n",
    "#     download_data(proposal_id, n_max_images, max_resolution, seed, data_dir='../data/observations/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def remove_large_files(directory, size_limit=2*1024*1024):  # default size_limit is set to 2MB\n",
    "#     for foldername, subfolders, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             filepath = os.path.join(foldername, filename)\n",
    "#             if os.path.getsize(filepath) > size_limit:\n",
    "#                 try:\n",
    "#                     os.remove(filepath)\n",
    "#                     print(f\"Removed {filepath}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error removing {filepath}: {e}\")\n",
    "\n",
    "# directory_path = '../data/observations/'\n",
    "# remove_large_files(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/observations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def get_abstracts_and_images(data_folder, abstracts_cycle_df):\n",
    "    # Lists to store results\n",
    "    images_list = []\n",
    "    abstracts_list = []\n",
    "\n",
    "    # Walk through data folder\n",
    "    for root, dirs, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                image_path = os.path.join(root, file)\n",
    "                proposal_id = root.split(\"proposal_\")[-1]  # Extract proposal id from the directory name\n",
    "                \n",
    "                # Extract abstract using the dataframe\n",
    "                abstract = abstracts_cycle_df[abstracts_cycle_df[\"ID\"] == int(proposal_id)][\"Abstract\"].values[0]\n",
    "\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                image = np.array(image)\n",
    "\n",
    "                # Pad image to square\n",
    "                h, w, c = image.shape\n",
    "                max_dim = max(h, w)\n",
    "                padded_image = np.ones((max_dim, max_dim, c), dtype=np.uint8) * 255\n",
    "\n",
    "                # Calculate top and left padding\n",
    "                y_offset = (max_dim - h) // 2\n",
    "                x_offset = (max_dim - w) // 2\n",
    "\n",
    "                padded_image[y_offset : y_offset + h, x_offset : x_offset + w, :] = image\n",
    "\n",
    "                images_list.append(padded_image)\n",
    "                abstracts_list.append(abstract)\n",
    "\n",
    "    return np.array(abstracts_list), np.array(images_list)\n",
    "\n",
    "data_folder = \"../data/observations/\"\n",
    "abstracts, images = get_abstracts_and_images(data_folder, abstracts_cycle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def serialize_example(abstract, image):\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Encode abstract to bytes\n",
    "    abstract_bytes = abstract.encode('utf-8')  \n",
    "\n",
    "    # Convert image to bytes\n",
    "    image_bytes = image.tobytes()\n",
    "\n",
    "    feature = {\n",
    "    'abstract': _bytes_feature(abstract_bytes),\n",
    "    'image': _bytes_feature(image_bytes),\n",
    "    'image_height': _int64_feature(height),\n",
    "    'image_width': _int64_feature(width)\n",
    "    }\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "with tf.io.TFRecordWriter('../data/observations.tfrecord') as writer:\n",
    "    for abstract, image in zip(abstracts, images):\n",
    "        example = serialize_example(abstract, image)\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/smsharma/Projects/multimodal-data/notebooks/create_dataset.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/smsharma/Projects/multimodal-data/notebooks/create_dataset.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m make_dataloader, create_input_iter\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/smsharma/Projects/multimodal-data/notebooks/create_dataset.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m files \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m../data/observations.tfrecord\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/smsharma/Projects/multimodal-data/notebooks/create_dataset.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ds \u001b[39m=\u001b[39m make_dataloader(files, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from models.dataset_utils import make_dataloader, create_input_iter\n",
    "\n",
    "files = ['../data/observations.tfrecord']\n",
    "ds = make_dataloader(files, batch_size=32, seed=42)\n",
    "create_input_iter(ds)\n",
    "\n",
    "image, caption = next(iter(ds))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image[0], vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[49406,  1746, 13690, ...,   537, 36128, 49407],\n",
       "       [49406,  1746, 13690, ...,   537, 36128, 49407],\n",
       "       [49406,  1746, 13690, ...,   537, 36128, 49407],\n",
       "       ...,\n",
       "       [49406, 14171,  5357, ..., 49407, 49407, 49407],\n",
       "       [49406, 14171,  5357, ..., 49407, 49407, 49407],\n",
       "       [49406, 14171,  5357, ..., 49407, 49407, 49407]]), 'attention_mask': array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption = caption.numpy().tolist()\n",
    "caption = [c.decode('utf-8') for c in caption]\n",
    "\n",
    "tokenizer(\n",
    "            caption,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=300,\n",
    "            return_tensors=\"np\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
