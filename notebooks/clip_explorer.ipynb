{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from models.models import CLIPTextTransformer, CLIPVisionTransformer, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "caption = \"Supernova (SN) 2019ehk in M100 is the closest known Calcium-rich (Ca-rich) transient and the only object in this class with an X-ray detection. Prompt, high-cadence follow-up of this transient across the EM spectrum, in addition to pre-explosion HST imaging, has indicated that the progenitor star was likely low mass and surrounded by dense circumstellar material (CSM) whose geometry/density was capable of producing luminous X-ray emission as well as a double-peaked light curve. The close proximity of SN 2019ehk provides the first opportunity to track the photometric evolution of a Ca-rich transient at late phases (>300 days) when the SN luminosity is governed by radioactive decay and/or additional power sources e.g., CSM, and is too faint for ground-based observatories. These objects typically decrease in magnitude rapidly and thus their late-time decline rate and power source is unknown. Here we propose multi-color imaging of SN 2019ehk in order to understand its late-time bolometric behavior and to constrain the total mass of Ni-56 synthesized in the explosion. This will allow us to test whether SN 2019ehk is powered solely by radioactive decay or by additional CSM at large distances from the progenitor system.\"\n",
    "\n",
    "txt_inputs = tokenizer(\n",
    "                    4 * [caption],\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=300,\n",
    "                    return_tensors=\"np\",\n",
    "                )\n",
    "txt_inputs = {k: txt_inputs[k] for k in [\"input_ids\", \"attention_mask\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_config = {\n",
    "    \"dtype\": \"float32\",\n",
    "    \"activations\": [\"gelu\"],\n",
    "    \"use_bias\": False,\n",
    "    \"force_scale\": False,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"mlp_dropout_rate\": 0.0,\n",
    "    \"unroll\": 100,\n",
    "    \"gradient_checkpointing\": False,\n",
    "    \"eos_token_id\": 49407,\n",
    "    \"vocab_size\": 50000,\n",
    "    \"hidden_size\": 512,\n",
    "    \"max_length\": 300,\n",
    "    \"num_layers\": 5,\n",
    "    \"use_rmsnorm\": True,\n",
    "    \"ln_type\": \"normformer\",\n",
    "    \"num_heads\": 8,\n",
    "    \"position_embedding_type\": \"rotary\",\n",
    "    \"use_causal_mask\": False,\n",
    "    \"mlp_dim\": 1024\n",
    "  }\n",
    "\n",
    "vision_config ={\n",
    "  \"position_embedding_type\": \"sincos2d\",\n",
    "  \"dtype\": \"float32\",\n",
    "  \"activations\": [\"gelu\"],\n",
    "  \"use_bias\": False,\n",
    "  \"force_scale\": False,\n",
    "  \"attention_dropout\": 0.0,\n",
    "  \"mlp_dropout_rate\": 0.0,\n",
    "  \"use_cls_token\": False,\n",
    "  \"unroll\": 100,\n",
    "  \"gradient_checkpointing\": True,\n",
    "  \"image_size\": 256,\n",
    "  \"hidden_size\": 512,\n",
    "  \"patch_size\": 16,\n",
    "  \"num_layers\": 5,\n",
    "  \"use_rmsnorm\": True,\n",
    "  \"ln_type\": \"normformer\",\n",
    "  \"num_heads\": 8,\n",
    "  \"use_causal_mask\": False,\n",
    "  \"mlp_dim\": 1024\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer = CLIPTextTransformer(**text_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 300), (4, 300))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_inputs['input_ids'].shape, txt_inputs['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "transformer.init_with_output(key, txt_inputs['input_ids'], txt_inputs['attention_mask']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = CLIPVisionTransformer(**vision_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Input image size (505*512) doesn't match model (256*256).\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import jax.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(\"../data/observations/proposal_15727/hst_15727_01_wfc3_ir_total_ie0w01_drz.jpg\")\n",
    "\n",
    "# Convert to RGB and to tensor\n",
    "img = img.convert('RGB')\n",
    "img = np.array(img)\n",
    "\n",
    "vit.init_with_output(key, np.array(4 * [img]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Input image size (505*512) doesn't match model (256*256).\n"
     ]
    }
   ],
   "source": [
    "clip = CLIPModel(text_config=text_config, vision_config=vision_config, projection_dim=256)\n",
    "outputs, params = clip.init_with_output(key, txt_inputs['input_ids'], np.array(4 * [img]), txt_inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-1.405358, dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mini_batch_sigmoid_loss(text_embeds, image_embeds, logit_scale, logit_bias, negative_samples):\n",
    "    \"\"\"Positive samples are on the diagonal\"\"\"\n",
    "    bs = text_embeds.shape[0]\n",
    "    if negative_samples:\n",
    "        labels = -np.ones((bs, bs))\n",
    "    else:\n",
    "        labels = 2 * np.eye(bs) - np.ones((bs, bs))\n",
    "    logits = np.matmul(text_embeds, image_embeds.T) * logit_scale + logit_bias\n",
    "    return -np.mean(np.log(1 + np.exp(-labels * logits)))\n",
    "\n",
    "def sigmoid_loss(outputs):\n",
    "    text_embeds = outputs[\"text_embeds\"]\n",
    "    image_embeds = outputs[\"image_embeds\"]\n",
    "    logit_scale = outputs[\"logit_scale\"]\n",
    "    logit_bias = outputs[\"logit_bias\"]\n",
    "    \n",
    "    bs = text_embeds.shape[0]\n",
    "\n",
    "    # Compute the positive samples loss\n",
    "    loss = mini_batch_sigmoid_loss(text_embeds, image_embeds, logit_scale, logit_bias, negative_samples=False)\n",
    "\n",
    "    # Create a tensor of all shifted versions of image embeddings\n",
    "    shifted_image_embeds = np.stack([np.roll(image_embeds, shift=-i, axis=0) for i in range(1, bs)])\n",
    "\n",
    "    # Compute the negative samples logits using einsum\n",
    "    all_neg_logits = np.einsum('bi,aji->abj', text_embeds, shifted_image_embeds)\n",
    "    all_neg_logits = all_neg_logits * logit_scale + logit_bias\n",
    "\n",
    "    neg_labels = -np.ones(all_neg_logits.shape)\n",
    "    neg_loss = -np.mean(np.log(1 + np.exp(-neg_labels * all_neg_logits)))\n",
    "\n",
    "    loss = (loss + (bs - 1) * neg_loss) / bs\n",
    "\n",
    "    return loss\n",
    "\n",
    "sigmoid_loss(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
