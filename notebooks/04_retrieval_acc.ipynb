{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3a1bfa-d17d-49c5-a009-eb7b82b56120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "from matplotlib import cm\n",
    "cmap = matplotlib.colormaps.get_cmap('viridis_r')\n",
    "\n",
    "# Ignore warning\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.MatplotlibDeprecationWarning)\n",
    "\n",
    "# Get plot params\n",
    "\n",
    "from plot_params import params\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "# Set default colors to load at will\n",
    "cols_default = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb91a7d-26a2-45a0-87aa-26e0478a6658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3036b9b-cbde-4afd-ba3c-246ccf35e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmsharma\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "! wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c989d78b-c14a-4f9d-8af5-77fc8475050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'run_labels' contains the names of the runs you are interested in\n",
    "# # Define it based on your requirements\n",
    "# run_labels = ['pretty-aardvark-45',\n",
    "#              'devout-hill-47',\n",
    "#               'vibrant-feather-50',\n",
    "#               'spring-snowball-56',\n",
    "#               'fresh-jazz-58']\n",
    "\n",
    "# run_legends = ['Fine tune full', \n",
    "#               \"No summarization\",\n",
    "#               'Fine tune head',\n",
    "#                'Train from scratch',\n",
    "#                'Shuffle within batch']\n",
    "\n",
    "# # Creating the dictionary\n",
    "# run_dict = {run_labels[i]: run_legends[i] for i in range(len(run_labels))}\n",
    "\n",
    "# api = wandb.Api()\n",
    "# runs = api.runs(\"smsharma/multimodal-hubble\")\n",
    "\n",
    "# # Initialize dictionaries to hold the data for plotting\n",
    "# top5_data = {}\n",
    "# top10_data = {}\n",
    "\n",
    "# for run in runs:\n",
    "#     if run.name in run_labels:\n",
    "        \n",
    "#         # Fetch history for top 5 and top 10 accuracy\n",
    "#         history_top5 = run.history(keys=[\"val/top_5_accuracy\"])\n",
    "#         history_top10 = run.history(keys=[\"val/top_10_accuracy\"])  # assuming this key exists\n",
    "\n",
    "#         # Store the data for later plotting\n",
    "#         top5_data[run.name] = (history_top5['_step'], history_top5['val/top_5_accuracy'])\n",
    "#         top10_data[run.name] = (history_top10['_step'], history_top10['val/top_10_accuracy'])  # replace with correct key if different\n",
    "\n",
    "# # Plotting\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# # Plot for Top 5 Accuracy\n",
    "# for idx, (run_name, (steps, accuracy)) in enumerate(top5_data.items()):\n",
    "#     ls = '-' if run_dict[run_name] == \"Shuffle within batch\" else '-'\n",
    "#     axes[0].plot(list(200 * np.arange(1, len(steps) + 1)), list(accuracy), label=run_dict[run_name], lw=2, ls=ls)  # replace with correct key if different\n",
    "\n",
    "# axes[0].set_title(r\"\\textbf{Top-5}\\%\")\n",
    "# axes[0].set_xlabel(\"Training steps\")\n",
    "# axes[0].set_ylabel(\"Retrival accuracy\")\n",
    "# axes[0].axhline(0.05, color='grey', ls='--', lw=1.5)\n",
    "# axes[0].set_ylim(0, 0.35)\n",
    "# axes[0].set_xlim(-500, 20_000)\n",
    "\n",
    "# # Plot for Top 10 Accuracy\n",
    "# for run_name, (steps, accuracy) in top10_data.items():\n",
    "#     ls = '-' if run_dict[run_name] == \"Shuffle within batch\" else '-'\n",
    "#     axes[1].plot(list(200 * np.arange(1, len(steps) + 1)), list(accuracy), label=run_dict[run_name], lw=2, ls=ls)  # replace with correct key if different\n",
    "\n",
    "# axes[1].set_title(r\"\\textbf{Top-10}\\%\")\n",
    "# axes[1].set_xlabel(\"Training steps\")\n",
    "# axes[1].set_ylabel(\"Retrival accuracy\")\n",
    "# axes[1].axhline(0.1, color='grey', ls='--', lw=1.5)\n",
    "# axes[1].set_ylim(0, 0.6)\n",
    "# axes[1].set_xlim(-500, 20_000)\n",
    "# axes[1].text(10_000, 0.12, \"\\emph{Random expectation}\", fontsize=15)\n",
    "    \n",
    "# fig.suptitle(r\"\\textbf{Top-$k$ retrieval accuracy over fine tuning}\", fontsize=20)\n",
    "# axes[0].legend(frameon=True, framealpha=0.8, fontsize=15)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"../paper/plots/retrieval_acc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f541fa5-91c5-4cca-abe4-911304e049e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     11\u001b[0m run_legends \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tune (summaries)\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tune (abstract)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tune head (summaries)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;66;03m#    'Fine-tune (single concepts)',\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Change order to [1, 0, 2, 3, 4] for both run_labels and run_legends\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m run_labels \u001b[38;5;241m=\u001b[39m [run_labels[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]]\n\u001b[1;32m     21\u001b[0m run_legends \u001b[38;5;241m=\u001b[39m [run_legends[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]]\n\u001b[1;32m     22\u001b[0m cols_plot \u001b[38;5;241m=\u001b[39m [cols_default[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m run_legends \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tune (summaries)\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tune (abstract)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tune head (summaries)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;66;03m#    'Fine-tune (single concepts)',\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Change order to [1, 0, 2, 3, 4] for both run_labels and run_legends\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m run_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]]\n\u001b[1;32m     21\u001b[0m run_legends \u001b[38;5;241m=\u001b[39m [run_legends[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]]\n\u001b[1;32m     22\u001b[0m cols_plot \u001b[38;5;241m=\u001b[39m [cols_default[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "run_labels = ['glistening-kumquat-123',\n",
    "              'enchanting-lantern-125',\n",
    "              'passionate-sweetheart-127',\n",
    "              'fragrant-date-128',\n",
    "              'twinkling-tiger-126',\n",
    "            #   'compassionate-admirer-129',\n",
    "              ]\n",
    "\n",
    "run_legends = ['Fine-tune (summaries)', \n",
    "               'Fine-tune (abstract)',\n",
    "               \"Fine-tune head (summaries)\",\n",
    "               'Train from scratch (summaries)',\n",
    "               \"Shuffle within batch\",\n",
    "            #    'Fine-tune (single concepts)',\n",
    "               ]\n",
    "\n",
    "# Change order to [1, 0, 2, 3, 4] for both run_labels and run_legends\n",
    "run_labels = [run_labels[i] for i in [1, 0, 2, 3, 4]]\n",
    "run_legends = [run_legends[i] for i in [1, 0, 2, 3, 4]]\n",
    "cols_plot = [cols_default[i] for i in [1, 0, 2, 3, 4]]\n",
    "\n",
    "ls_list = ['-', '-', ':', '-', '--']\n",
    "cols_list = [cols_default[0], cols_default[1], cols_default[2], cols_default[5], cols_default[4]]\n",
    "\n",
    "# Creating the dictionary\n",
    "run_dict = {run_labels[i]: run_legends[i] for i in range(len(run_labels))}\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(\"smsharma/multimodal-hubble\")\n",
    "\n",
    "# Initialize dictionaries to hold the data for plotting\n",
    "top5_data = {}\n",
    "top10_data = {}\n",
    "\n",
    "for run in runs:\n",
    "    if run.name in run_labels:\n",
    "        \n",
    "        # Fetch history for top 5 and top 10 accuracy\n",
    "        history_top5 = run.history(keys=[\"val/loss\"])\n",
    "        history_top10 = run.history(keys=[\"val/top_10_accuracy\"])  # assuming this key exists\n",
    "\n",
    "        # Store the data for later plotting\n",
    "        top5_data[run.name] = (history_top5['_step'], history_top5['val/loss'])\n",
    "        top10_data[run.name] = (history_top10['_step'], history_top10['val/top_10_accuracy'])  # replace with correct key if different\n",
    "\n",
    "# Order top5_data and top10_data according to the run_labels list order\n",
    "import collections\n",
    "top5_data = collections.OrderedDict(sorted(top5_data.items()))\n",
    "top10_data = collections.OrderedDict(sorted(top10_data.items()))\n",
    "\n",
    "# Sort according to the run_labels\n",
    "top5_data = {k: top5_data[k] for k in run_labels}\n",
    "top10_data = {k: top10_data[k] for k in run_labels}\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12 * 1.1, 6 * 1.1))\n",
    "\n",
    "# Plot for Top 5 Accuracy\n",
    "for idx, (run_name, (steps, accuracy)) in enumerate(top5_data.items()):\n",
    "    axes[0].plot(list(200 * np.arange(1, len(steps) + 1)), list(accuracy), label=run_dict[run_name], lw=2., ls=ls_list[idx], color=cols_plot[idx])  # replace with correct key if different\n",
    "\n",
    "axes[0].set_title(r\"\\textbf{Validation loss} $\\downarrow$\")\n",
    "axes[0].set_xlabel(\"Training steps\")\n",
    "axes[0].set_ylabel(\"Validation loss\")\n",
    "# axes[0].axhline(0.05, color='grey', ls='--', lw=1.5)\n",
    "# axes[0].set_ylim(0, 0.3)\n",
    "axes[0].set_xlim(-500, 20_000)\n",
    "\n",
    "# Getting handles and labels from ax[0]\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "# Selecting half of the legend items\n",
    "half = 0  # len(handles) // 2\n",
    "selected_handles = handles[half:]\n",
    "selected_labels = labels[half:]\n",
    "\n",
    "axes[0].legend(handles[:half], labels[:half], frameon=True, framealpha=0.8, fontsize=15)\n",
    "\n",
    "# Plot for Top 10 Accuracy\n",
    "for idx, (run_name, (steps, accuracy)) in enumerate(top10_data.items()):\n",
    "    axes[1].plot(list(200 * np.arange(1, len(steps) + 1)), list(accuracy), label=run_dict[run_name], lw=2., ls=ls_list[idx], color=cols_plot[idx])  # replace with correct key if different\n",
    "\n",
    "axes[1].set_title(r\"\\textbf{Top-10\\% retrieval} $\\uparrow$\")\n",
    "axes[1].set_xlabel(\"Training steps\")\n",
    "axes[1].set_ylabel(\"Retrieval accuracy\")\n",
    "axes[1].axhline(0.1, color='grey', ls='--', lw=1.5)\n",
    "axes[1].set_ylim(0, 0.8)\n",
    "axes[1].set_xlim(-500, 20_000)\n",
    "axes[1].text(0, 0.06, r\"\\emph{Random expectation}\", fontsize=14)\n",
    "    \n",
    "fig.suptitle(r\"\\textbf{Validation metrics over training}\", fontsize=20)\n",
    "# axes[1].legend(frameon=True, framealpha=0.8, fontsize=15)\n",
    "\n",
    "# Place on the right, above 0.2 up from bottom\n",
    "axes[1].legend(selected_handles, selected_labels, frameon=False, framealpha=0.8, fontsize=14, loc='upper right', bbox_to_anchor=(1.0, 0.47))\n",
    "\n",
    "# Also add legend for the first plot, but with order reversed\n",
    "axes[0].legend(selected_handles[::-1], selected_labels[::-1], frameon=False, framealpha=0.8, fontsize=14, loc='upper right', bbox_to_anchor=(1.0, 0.55))\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"../paper/plots/val_metrics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c968a-737c-4d26-8a79-49647c68aeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
