{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.abstract_utils import read_abstracts_file\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/abstracts.cat\"\n",
    "\n",
    "abstracts_df = read_abstracts_file(filename)\n",
    "\n",
    "# Drop rows with missing Cycle\n",
    "abstracts_df = abstracts_df.dropna(subset=['Cycle'])\n",
    "abstracts_df = abstracts_df[abstracts_df['Cycle'] != '']\n",
    "\n",
    "# Convert Cycle and ID to int\n",
    "abstracts_df['Cycle'] = abstracts_df['Cycle'].astype(int)\n",
    "abstracts_df['ID'] = abstracts_df['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prop. Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Title</th>\n",
       "      <th>PI</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG/STIS/PAR</td>\n",
       "      <td></td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>STIS Pure Parallel Imaging Program: Cycle 12</td>\n",
       "      <td>Paul Goudfrooij</td>\n",
       "      <td>This is the default archival pure parallel pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO</td>\n",
       "      <td>GALAXIES</td>\n",
       "      <td>10001</td>\n",
       "      <td>12</td>\n",
       "      <td>Locating Ultraluminous X-Ray Sources</td>\n",
       "      <td>Philip Kaaret</td>\n",
       "      <td>We propose to observe ultraluminous X-ray sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO</td>\n",
       "      <td>AGN</td>\n",
       "      <td>10002</td>\n",
       "      <td>12</td>\n",
       "      <td>Detailed Study of X-ray Jets from a Complete S...</td>\n",
       "      <td>Eric Perlman</td>\n",
       "      <td>We propose deep followup HST and Chandra obse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO</td>\n",
       "      <td>GALAXIES</td>\n",
       "      <td>10003</td>\n",
       "      <td>12</td>\n",
       "      <td>Deep Chandra and Hubble Observations of NGC469...</td>\n",
       "      <td>Craig Sarazin</td>\n",
       "      <td>We propose 4 new Chandra observations of NGC4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO</td>\n",
       "      <td>AGN</td>\n",
       "      <td>10004</td>\n",
       "      <td>12</td>\n",
       "      <td>The Physics of Relativistic Jets: Chandra Imag...</td>\n",
       "      <td>F. Tavecchio</td>\n",
       "      <td>Extended jets have been a key target for Chan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prop. Type  Category     ID  Cycle  \\\n",
       "0  ENG/STIS/PAR            10000     12   \n",
       "1            GO  GALAXIES  10001     12   \n",
       "2            GO       AGN  10002     12   \n",
       "3            GO  GALAXIES  10003     12   \n",
       "4            GO       AGN  10004     12   \n",
       "\n",
       "                                               Title               PI  \\\n",
       "0       STIS Pure Parallel Imaging Program: Cycle 12  Paul Goudfrooij   \n",
       "1               Locating Ultraluminous X-Ray Sources    Philip Kaaret   \n",
       "2  Detailed Study of X-ray Jets from a Complete S...     Eric Perlman   \n",
       "3  Deep Chandra and Hubble Observations of NGC469...    Craig Sarazin   \n",
       "4  The Physics of Relativistic Jets: Chandra Imag...     F. Tavecchio   \n",
       "\n",
       "                                            Abstract  \n",
       "0   This is the default archival pure parallel pr...  \n",
       "1   We propose to observe ultraluminous X-ray sou...  \n",
       "2   We propose deep followup HST and Chandra obse...  \n",
       "3   We propose 4 new Chandra observations of NGC4...  \n",
       "4   Extended jets have been a key target for Chan...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep specific Cycles\n",
    "\n",
    "cycle_min = 0\n",
    "cycle_max = 32\n",
    "\n",
    "abstracts_cycle_df = abstracts_df[(abstracts_df['Cycle'] >= cycle_min) & (abstracts_df['Cycle'] <= cycle_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract_ids = abstracts_cycle_df['ID'].values\n",
    "# abstracts_cycle_df['Cycle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def remove_large_files(directory, size_limit=2*1024*1024):  # default size_limit is set to 2MB\n",
    "#     for foldername, subfolders, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             filepath = os.path.join(foldername, filename)\n",
    "#             if os.path.getsize(filepath) > size_limit:\n",
    "#                 try:\n",
    "#                     os.remove(filepath)\n",
    "#                     print(f\"Removed {filepath}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error removing {filepath}: {e}\")\n",
    "\n",
    "# directory_path = '../data/observations_v2/'\n",
    "# remove_large_files(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_filename = \"../data/summary_v1.csv\"\n",
    "\n",
    "summaries_df = pd.read_csv(summaries_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal_id</th>\n",
       "      <th>objects_phenomena</th>\n",
       "      <th>science_use_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14743</td>\n",
       "      <td>superluminous supernova, SN 2015bn, magnetar s...</td>\n",
       "      <td>late-time luminosity, proximity, sufficiently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6507</td>\n",
       "      <td>spiral density waves, self-propagating star fo...</td>\n",
       "      <td>ages of the stellar populations, color gradien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14249</td>\n",
       "      <td>neutron stars, radio-pulsars, 166 Myr old rad...</td>\n",
       "      <td>long-term evolution of neutron stars, surface...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8781</td>\n",
       "      <td>blue star, luminous blue variable, major outb...</td>\n",
       "      <td>mass loss rate, temperature, luminosity, chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556</td>\n",
       "      <td>neutral hydrogen gas, Damped Lyman-alpha syste...</td>\n",
       "      <td>tracking neutral hydrogen gas, evolution of ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proposal_id                                  objects_phenomena  \\\n",
       "0        14743  superluminous supernova, SN 2015bn, magnetar s...   \n",
       "1         6507  spiral density waves, self-propagating star fo...   \n",
       "2        14249   neutron stars, radio-pulsars, 166 Myr old rad...   \n",
       "3         8781   blue star, luminous blue variable, major outb...   \n",
       "4        10556  neutral hydrogen gas, Damped Lyman-alpha syste...   \n",
       "\n",
       "                                   science_use_cases  \n",
       "0  late-time luminosity, proximity, sufficiently ...  \n",
       "1  ages of the stellar populations, color gradien...  \n",
       "2   long-term evolution of neutron stars, surface...  \n",
       "3   mass loss rate, temperature, luminosity, chem...  \n",
       "4  tracking neutral hydrogen gas, evolution of ne...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stars, color-magnitude diagrams (CMDs), Leo I dwarf spheroidal galaxy, WFPC2, ACS/WFC, bluer wavelengths, higher spatial resolution, larger field-of-view, metallicity distribution'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df[summaries_df[\"proposal_id\"] == 10520][\"objects_phenomena\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 19:38:53.811936: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-23 19:38:53.812521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-23 19:38:53.854427: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(abstract, summary, image):\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Encode abstract to bytes\n",
    "    abstract_bytes = abstract.encode('utf-8')  \n",
    "    summary_bytes = summary.encode('utf-8')  \n",
    "\n",
    "    # Convert image to bytes\n",
    "    image_bytes = image.tobytes()\n",
    "\n",
    "    feature = {\n",
    "        'abstract': _bytes_feature(abstract_bytes),\n",
    "        'summary': _bytes_feature(summary_bytes),\n",
    "        'image': _bytes_feature(image_bytes),\n",
    "        'image_height': _int64_feature(height),\n",
    "        'image_width': _int64_feature(width)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def write_tfrecord(abstracts, summaries, images, filename, metadata_file):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for abstract, summary, image in zip(abstracts, summaries, images):\n",
    "            tf_example = serialize_example(abstract, summary, image)\n",
    "            writer.write(tf_example)\n",
    "    \n",
    "    # Write metadata to the auxiliary file\n",
    "    with open(metadata_file, 'a') as meta_file:\n",
    "        meta_file.write(f\"{filename}: {len(images)} images\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size is 3185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6597cb8e5b04202807e3b16436ac0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Images:   0%|          | 0/31859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing record 1\n",
      "Writing record 2\n",
      "Writing record 3\n",
      "Writing record 4\n",
      "Writing record 5\n",
      "Writing record 6\n",
      "Writing record 7\n",
      "Writing record 8\n",
      "Writing record 9\n",
      "Writing record 10\n",
      "Writing final record 11\n"
     ]
    }
   ],
   "source": [
    "def get_abstracts_and_images_and_write_tfrecords(data_folder, tfrecords_folder, abstracts_cycle_df, summaries_df, num_tfrecords, num_train_tfrecords):\n",
    "    \n",
    "    # Lists to store results\n",
    "    images_list = []\n",
    "    abstracts_list = []\n",
    "    summaries_list = []\n",
    "\n",
    "    # Collect directories that contain .jpg files and match the \"proposal_\" pattern, excluding unwanted directories\n",
    "    directories_with_images = [os.path.join(r, d)\n",
    "                               for r, dirs, files in os.walk(data_folder)\n",
    "                               for d in dirs\n",
    "                               if d.startswith(\"proposal_\") and not d.endswith('.ipynb_checkpoints')]\n",
    "\n",
    "    # Shuffle the list of directories\n",
    "    random.shuffle(directories_with_images)\n",
    "\n",
    "    # Get the total number of jpg files to be processed for the progress bar\n",
    "    total_files = sum([len(files) for r, d, files in os.walk(data_folder) if any(file.endswith('.jpg') for file in files)])\n",
    "\n",
    "    # Calculate the chunk size\n",
    "    chunk_size = total_files // num_tfrecords if total_files >= num_tfrecords else 1\n",
    "\n",
    "    print(f\"Chunk size is {chunk_size}\")\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    pbar = tqdm(total=total_files, desc='Processing Images')\n",
    "\n",
    "    # Initialize the file number\n",
    "    file_num = 1\n",
    "    metadata_file = f'{tfrecords_folder}/metadata.txt'\n",
    "    \n",
    "    # Clear the metadata file if it exists\n",
    "    if os.path.exists(metadata_file):\n",
    "        os.remove(metadata_file)\n",
    "\n",
    "    # Create tfrecords folder if it doesn't exist\n",
    "    os.makedirs(tfrecords_folder, exist_ok=True)\n",
    "\n",
    "    # Walk through data folder\n",
    "    for directory in directories_with_images:\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                \n",
    "                image_path = os.path.join(directory, file)\n",
    "                proposal_id = directory.split(\"proposal_\")[-1]  # Extract proposal id from the directory name\n",
    "                \n",
    "                # Extract abstract using the dataframe\n",
    "                abstract = abstracts_cycle_df[abstracts_cycle_df[\"ID\"] == int(proposal_id)][\"Abstract\"].values[0]\n",
    "                category = abstracts_cycle_df[abstracts_cycle_df[\"ID\"] == int(proposal_id)][\"Category\"].values[0]\n",
    "\n",
    "                objects_phenomena = summaries_df[summaries_df[\"proposal_id\"] == int(proposal_id)][\"objects_phenomena\"].values[0]\n",
    "                science_use_cases = summaries_df[summaries_df[\"proposal_id\"] == int(proposal_id)][\"science_use_cases\"].values[0]\n",
    "\n",
    "                summary = f\"{objects_phenomena}; {science_use_cases}\"\n",
    "\n",
    "                if category is not None:\n",
    "                    abstract = f\"Category: {category}. {abstract}\"\n",
    "                    \n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                image = np.array(image)\n",
    "\n",
    "                # Pad image to square\n",
    "                h, w, c = image.shape\n",
    "                max_dim = max(h, w)\n",
    "                padded_image = np.ones((max_dim, max_dim, c), dtype=np.uint8) * 255\n",
    "\n",
    "                # Calculate top and left padding\n",
    "                y_offset = (max_dim - h) // 2\n",
    "                x_offset = (max_dim - w) // 2\n",
    "\n",
    "                padded_image[y_offset : y_offset + h, x_offset : x_offset + w, :] = image\n",
    "\n",
    "                images_list.append(padded_image)\n",
    "                abstracts_list.append(abstract)\n",
    "                summaries_list.append(summary)\n",
    "                \n",
    "                pbar.update(1)  # Update the progress bar\n",
    "\n",
    "                # If the length of the lists reaches the chunk size, write to a TFRecord file\n",
    "                if len(images_list) >= chunk_size:\n",
    "                    print(f\"Writing record {file_num}\")\n",
    "\n",
    "                    # Either train or val\n",
    "                    if file_num <= num_train_tfrecords:\n",
    "                        filename = f\"{tfrecords_folder}/observations_train_{file_num}.tfrecord\"\n",
    "                    else:\n",
    "                        filename = f\"{tfrecords_folder}/observations_val_{file_num}.tfrecord\"\n",
    "                        \n",
    "                    write_tfrecord(abstracts_list, summaries_list, images_list, filename, metadata_file)\n",
    "                    \n",
    "                    # Reset the images and abstracts lists\n",
    "                    images_list = []\n",
    "                    abstracts_list = []\n",
    "                    summaries_list = []\n",
    "                    \n",
    "                    file_num += 1  # Increment the file number\n",
    "\n",
    "    # Write the remaining records to a TFRecord file if any\n",
    "    if images_list:\n",
    "        print(f\"Writing final record {file_num}\")\n",
    "        filename = f\"{tfrecords_folder}/observations_val_{file_num}.tfrecord\"\n",
    "        write_tfrecord(abstracts_list, summaries_list, images_list, filename, metadata_file)\n",
    "\n",
    "    pbar.close()  # Close the progress bar\n",
    "\n",
    "tfrecords_folder = \"../data/tfrecords_v4/\"\n",
    "data_folder = \"../data/observations_v1/\"\n",
    "num_tfrecords = 10\n",
    "num_train_tfrecords = 9\n",
    "\n",
    "get_abstracts_and_images_and_write_tfrecords(data_folder, tfrecords_folder, abstracts_cycle_df, summaries_df, num_tfrecords, num_train_tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        str\n",
       "\u001b[0;31mString form:\u001b[0m isolated black holes, old stellar population, background stars, Galactic bulge, microlensing even <...>  duration events, OGLE detects six T>300 days events each year, monitoring a few T>300-day events\n",
       "\u001b[0;31mLength:\u001b[0m      405\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "str(object='') -> str\n",
       "str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
       "\n",
       "Create a new string object from the given object. If encoding or\n",
       "errors is specified, then the object must expose a data buffer\n",
       "that will be decoded using the given encoding and error handler.\n",
       "Otherwise, returns the result of object.__str__() (if defined)\n",
       "or repr(object).\n",
       "encoding defaults to sys.getdefaultencoding().\n",
       "errors defaults to 'strict'."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_folder = \"../data/observations_v1/\"\n",
    "save_dir = \"../paper/plots/data/\"\n",
    "\n",
    "# Collect directories that contain .jpg files and match the \"proposal_\" pattern, excluding unwanted directories\n",
    "directories_with_images = [os.path.join(r, d)\n",
    "                           for r, dirs, files in os.walk(data_folder)\n",
    "                           for d in dirs\n",
    "                           if d.startswith(\"proposal_\") and not d.endswith('.ipynb_checkpoints')]\n",
    "random.seed(99999)\n",
    "random.seed(1e9 + 5345)\n",
    "random.shuffle(directories_with_images)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 4, figsize=(20,4))\n",
    "\n",
    "ii = 0\n",
    "\n",
    "for directory in directories_with_images[:4]:\n",
    "    proposal_id = directory.split(\"proposal_\")[-1]  # Extract proposal id from the directory name\n",
    "\n",
    "    for file in os.listdir(directory)[0:1]:\n",
    "        if file.endswith(\".jpg\"):      \n",
    "            image_path = os.path.join(directory, file)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image = np.array(image)\n",
    "\n",
    "            # Pad image to square\n",
    "            h, w, c = image.shape\n",
    "            max_dim = max(h, w)\n",
    "            padded_image = np.ones((max_dim, max_dim, c), dtype=np.uint8) * 255\n",
    "\n",
    "            # Calculate top and left padding\n",
    "            y_offset = (max_dim - h) // 2\n",
    "            x_offset = (max_dim - w) // 2\n",
    "\n",
    "            padded_image[y_offset : y_offset + h, x_offset : x_offset + w, :] = image\n",
    "\n",
    "            # ax[ii].imshow(padded_image)\n",
    "\n",
    "            # Extract abstract using the dataframe\n",
    "            abstract = abstracts_cycle_df[abstracts_cycle_df[\"ID\"] == int(proposal_id)][\"Abstract\"].values[0]\n",
    "            category = abstracts_cycle_df[abstracts_cycle_df[\"ID\"] == int(proposal_id)][\"Category\"].values[0]\n",
    "\n",
    "            objects_phenomena = summaries_df[summaries_df[\"proposal_id\"] == int(proposal_id)][\"objects_phenomena\"].values[0]\n",
    "            science_use_cases = summaries_df[summaries_df[\"proposal_id\"] == int(proposal_id)][\"science_use_cases\"].values[0]\n",
    "\n",
    "            summary = f\"{objects_phenomena}; {science_use_cases}\"\n",
    "\n",
    "            with open(save_dir + f\"/sum_{ii}.txt\", 'w') as file:\n",
    "                file.write(summary)\n",
    "\n",
    "            with open(save_dir + f\"/abs_{ii}.txt\", 'w') as file:\n",
    "                file.write(abstract)\n",
    "\n",
    "            with open(save_dir + f\"/id_{ii}.txt\", 'w') as file:\n",
    "                file.write(proposal_id)\n",
    "\n",
    "            with open(save_dir + f\"/cycle_{ii}.txt\", 'w') as file:\n",
    "                file.write(cycle)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(padded_image)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_dir + f\"/img_{ii}.pdf\")\n",
    "            plt.close()\n",
    "\n",
    "            if category is not None:\n",
    "                abstract = f\"Category: {category}. {abstract}\"\n",
    "\n",
    "            ii += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millisecond pulsar, B1855+09, white-dwarf companion, helium white dwarf, parallax; quantitative comparisons between theoretical and observational properties, interior structure and atmosphere of the white dwarf, cooling age of the white dwarf, age of the pulsar'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Category: STELLAR POPULATIONS.  Recently, deep color-magnitude diagrams (CMDs) from HST data revealed that several massive intermediate-age star clusters in the Magellanic Clouds exhibit extended main-sequence turn-offs (eMSTOs), and in some cases also dual red clumps. This poses serious questions regarding the mechanisms responsible for the formation of massive star clusters and their well-known light-element abundance variations. The nature of eMSTOs is currently a hotly debated topic of study. Several recent studies indicate that the eMSTOs are caused by an age spread of about 100-500 Myr among cluster stars, while other studies indicate that eMSTOs can be caused by a coeval population in which the relevant stars span a range of rotation velocities. Formal evidence to (dis-)prove either scenario still remains at large, mainly because the available stellar tracks that incorporate the effects of rotation are only available for masses > 1.7 Msun whereas the stars in the known eMSTOs of intermediate-age clusters are less massive. To circumvent this issue, we identified a massive star cluster in the Large Magellanic Cloud (LMC) that has the right dynamical properties to host an eMSTO along with an age at which the effects of age spreads to CMD morphology are substantially different from those of spreads of rotation rates: the ~600 Myr old cluster NGC 1831. We propose to obtain deep WFC3/UVIS imaging with filters F336W and F814W to analyze the morphologies of the MSTO and upper MS regions of NGC 1831 at high precision and compare with model predictions. This will have a lasting impact on our understanding of the eMSTO phenomenon and of star cluster formation in general.'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smsharma-multimodal-hubble] *",
   "language": "python",
   "name": "conda-env-smsharma-multimodal-hubble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
