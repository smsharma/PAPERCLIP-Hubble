{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79a016b9-c920-49f2-93f7-bffa510bb756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import outlines\n",
    "import outlines.models as models\n",
    "import outlines.text as text\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from pydantic import BaseModel, Field, constr, conlist\n",
    "from enum import Enum\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "61c50865-a4cb-4501-811e-6115d93f6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "@outlines.prompt\n",
    "def prompt_fn(sum):\n",
    "    \"\"\"Please produce a list of around concepts characterizing prominent objects, phenomena, and science use cases of images observed by the Hubble Space Telescope.\n",
    "\n",
    "Here are some examples of objects:\n",
    "\n",
    "{{sum}}\n",
    "\n",
    "Follow these instructions exactly in your answer:\n",
    "- Do not output empty strings as elements.\n",
    "- Make sure that the list covers a diverse range of astronomical concepts, with items as different from each other as possible. \n",
    "- Do not give specific names of objects, to make sure you span the widest possible range of concepts (e.g., \"dwarf galaxy\" is allowed, but NOT \"Fornax\", \"Terzan 5\", or  \"NGC6440\").\n",
    "- Do not return terms undescriptive of observations, e.g. \"sloshing\", \"adiabatic\", \"interactions\". Returning concrete physics objects, concepts, or phenomena.\n",
    "- Only output scientifically meaningful terms that are descriptive of Hubble Space Telescope observations.\n",
    "- Do not duplicate entries. Do not reference any telescopes, observatories, or surveys.\n",
    "- Do not include units like \"angular diameter distance\", \"parsec\", or any other concepts that will not correlate with images of observations.\n",
    "- Use the above example list of objects only as inspiration to infer broad classes of objects.\n",
    "- Make sure each concept is succint, never more than 5 words.\n",
    "- Answer in JSON format.\n",
    "- The JSON should have the following keys {\"galaxies\", \"stellar_physics\", \"exoplanets_planet_formation\", \"stellar_populations\", \"supermassive_black_holes\", \"solar_system\", \"integalactic_medium\", \"large_scale_structure\"} reflecting rough observation categories.\n",
    "- Each category will have a list of objects and/or astronomical phenomena.\n",
    "- Output up to 20 items and no more in each category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b9fcbb2-033e-492d-9156-7381300ae6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "summaries_filename = \"../data/summary_v2.csv\"\n",
    "summaries_df = pd.read_csv(summaries_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0944bb5b-bf29-431f-bb4c-b059dae5f541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [08:12<00:00, 98.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "n_examples = 100\n",
    "n_tries = 5\n",
    "\n",
    "sum1 = []\n",
    "prompt_list = []\n",
    "for i_try in tqdm(range(n_tries)):\n",
    "    \n",
    "    prompt = prompt_fn('\\n'.join(summaries_df['objects_phenomena'].values[i_try * n_examples:(i_try + 1) * n_examples]))\n",
    "    prompt_list.append(prompt)\n",
    "\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-4-1106-preview\",\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert astrophysicist and a helpful assistant designed to output JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    output = json.loads(response.choices[0].message.content)\n",
    "    list_of_lists = [output[key] for key in output.keys()]\n",
    "    sum1 += [item for sublist in list_of_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bbb3699-d981-4674-a98e-575528fc3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip special characters\n",
    "\n",
    "import string \n",
    "\n",
    "special_chars = set(string.punctuation) \n",
    "\n",
    "cleaned_sum1 = []\n",
    "for s in sum1:\n",
    "    start_idx = 0\n",
    "    while start_idx < len(s) and (s[start_idx] in special_chars or s[start_idx].isspace()):\n",
    "        start_idx += 1\n",
    "        \n",
    "    cleaned_sum1.append(s[start_idx:])\n",
    "        \n",
    "cleaned_sum1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6dc82928-96c8-41a3-9a54-56b012ab55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates and combine lists\n",
    "\n",
    "cleaned2_sum1 = []\n",
    "for s in cleaned_sum1:\n",
    "    if s == '':\n",
    "        continue\n",
    "        \n",
    "    if s.lower() not in map(str.lower, cleaned2_sum1):\n",
    "        cleaned2_sum1.append(s.lower())\n",
    "\n",
    "# cleaned2_sum1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ef497b8-a0db-48d5-a2eb-e199802cf686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned2_sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c436012-cd13-402e-83cc-8e23f9237972",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/sum1_gpt4.txt\", \"w\") as file:\n",
    "    # Write each string to the file\n",
    "    for string in cleaned2_sum1:\n",
    "        file.write(string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4665e558-5889-4ca7-8f9d-60e569328a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.abstract_utils import read_abstracts_file\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "filename = \"../data/abstracts.cat\"\n",
    "\n",
    "abstracts_df = read_abstracts_file(filename)\n",
    "\n",
    "# Drop rows with missing Cycle\n",
    "abstracts_df = abstracts_df.dropna(subset=['Cycle'])\n",
    "abstracts_df = abstracts_df[abstracts_df['Cycle'] != '']\n",
    "\n",
    "# Convert Cycle and ID to int\n",
    "abstracts_df['Cycle'] = abstracts_df['Cycle'].astype(int)\n",
    "abstracts_df['ID'] = abstracts_df['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c93b4416-a34c-4f52-8fea-6d948b193bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@outlines.prompt\n",
    "def prompt_fn(abs, cats):\n",
    "    \"\"\"<s>[INST] The following is a successful proposal abstract for the Hubble Space Telescope: \"{{abs}}\"\n",
    "\n",
    "The following is a list of categories (astronomical concepts) that this abstract could correspond to.\n",
    "\n",
    "{{cats}}\n",
    "\n",
    "Please answer which of these listed concepts best describes this proposal, based on the objects and phenomena mentioned in the abstract.\n",
    "The concept should meaningfully be present in the abstract and the eventual observation.\n",
    "\n",
    "- For example, \"The locations of supernovae {SNe} in the local stellar and gaseous environment in galaxies, as measured in high spatial resolution WFPC2 and ACS images, contain important clues to their progenitor stars.\" should return \"supernova\".\n",
    "- If the abstract centers calibration and/or instrumentation efforts, return calibration or instrumention\".\n",
    "\n",
    "If no concept make sense, return \"None\". [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2087613-b10f-402d-b647-55832105caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlines.generate import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7213627-6e6e-4038-946a-8bb30e356de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = choice(model, cleaned2_sum1 + [\"None\", \"calibration or instrumention\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec27247e-24c0-47ab-add0-515c451ed657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' We propose a comprehensive survey of CO column densities in diffuse molecular clouds extracted from archival spectra. The primary dataset involves STIS high resolution spectra, supplemented by high quality data obtained with GHRS. We will examine the 12C16O/13C16O ratio in 15 to 20 directions and the CO/H2 ratio in over 30 sight lines, thereby more than doubling the number of clouds with precisely determined column densities. The survey will provide the basis for the most thorough comparison between observations and theoretical models of CO photochemistry. Since CO is used as a diagnostic of the physical conditions in many astronomical environments, accurate models are essential. The comparison made with our survey will lead to more accurate models than those available today. Particular attention will be given to discerning the CO column where self shielding significantly reduces photodissociation. The trends in the CO/H2 ratio, especially for CO column densities much greater than those obtained from observations with the Copernicus satellite, will provide the means for more precise estimates of molecular cloud masses from CO emission at radio wavelengths in our Galaxy and others. Better cloud masses are needed in studies describing how star formation has changed over time.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = abstracts_df['Abstract'].values[-77]  # -77\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83749eb5-d084-4021-ac9e-19c19020be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Magnetars'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_fn(abstract, ', '.join(cleaned2_sum1 + [\"calibration or instrumention\"]))\n",
    "result = generator(prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "503288fd-20e3-4563-b0cb-8876f1dc5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# data_folder = \"../data/observations_v1/\"\n",
    "\n",
    "# def get_abstracts(data_folder, min_abstract=0, max_abstracts=99999999):\n",
    "    \n",
    "#     # Lists to store results\n",
    "#     proposal_id_list = []\n",
    "#     result_list = []\n",
    "\n",
    "#     # Collect directories that contain .jpg files and match the \"proposal_\" pattern, excluding unwanted directories\n",
    "#     directories_with_images = [os.path.join(r, d)\n",
    "#                                for r, dirs, files in os.walk(data_folder)\n",
    "#                                for d in dirs\n",
    "#                                if d.startswith(\"proposal_\") and not d.endswith('.ipynb_checkpoints')]\n",
    "\n",
    "#     # Walk through data folder\n",
    "#     for directory in tqdm(directories_with_images[min_abstract:max_abstracts]):\n",
    "#         proposal_id = directory.split(\"proposal_\")[-1]  # Extract proposal id from the directory name\n",
    "\n",
    "#         # Extract abstract using the dataframe\n",
    "#         abstract = abstracts_df[abstracts_df[\"ID\"] == int(proposal_id)][\"Abstract\"].values[0]\n",
    "#         prompt = prompt_fn(abstract, ', '.join(cleaned2_sum1 + [\"calibration or instrumention\"]))\n",
    "#         result = generator(prompt)\n",
    "#         print(f\"{result}:{abstract}\")\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         proposal_id_list.append(proposal_id)\n",
    "#         result_list.append(result)\n",
    "\n",
    "#     return proposal_id_list, result_list\n",
    "        \n",
    "# proposal_id_list, result_list = get_abstracts(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf3fbde4-e6e8-42af-9e2f-a8a0b1a2fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'proposal_id': proposal_id_list,\n",
    "    'objects_phenomena': result_list,\n",
    "})\n",
    "\n",
    "df.to_csv('../data/summary_sum1_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea166adf-a280-483e-9582-179497fb0f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
